{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QXjcLMHzq-Dy"
   },
   "source": [
    "# Lab 3: Rigid Registration\n"
   ],
   "id": "QXjcLMHzq-Dy"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7qeF8efHHLIo"
   },
   "source": [
    "## Remainder\n",
    "\n",
    "Among other useful information, it tells you to make a copy of this Colab notebook BEFORE you try to run it:\n",
    "\n",
    "- Make a copy on your own Colab space by clicking on the `copy to drive` button.\n",
    "- Alternatively you could go to the menu `File > Save a copy in Drive`\n",
    "- Then, open your new file on a new tap and rename it, and you’re ready to start tinkering with the code\n",
    "- Look carefully at the existing code before you execute it. Try to understand what the code is doing. Part of your learning outcome is to understand it, and we will quiz you about it.\n",
    "- In several places of the code, you’ll find `#__________TO DO_________`.\n",
    "There you should introduce your code.\n",
    "\n",
    "Once you are done, submit this notebook by the lab deadline, with the cells executed and including your **answers** in the text fields in $\\color{red}{\\text{red}}$ color.\n",
    "\n",
    "Use `$\\color{red}{\\text{This is my red text}}$` to write \"$\\color{red}{\\text{This is my red text}}$\"."
   ],
   "id": "7qeF8efHHLIo"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Kv_muqoq-D5"
   },
   "source": [
    "# Loading the required files\n",
    "You can load into the temporal workspace of Colab the following required files:\n",
    "\n",
    "*   the data files `LAB3_data`. Download them from Moodle to your computer and uncompress them.\n",
    "\n",
    "You should copy these files from your computer using the function `files.upload()`. Use the `Choose Files` button to upload both files from your local drive.\n",
    "\n",
    "Don't use Safari, it is preferable to use google chrome"
   ],
   "id": "6Kv_muqoq-D5"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KrPZaqmiq-D3"
   },
   "source": [
    "## Goals of this lab\n",
    "The aim of this lab is to develop competences regarding teamwork and problem solving. By developing the proposed activity you will also become familiar with SIFT and planar transformations for rigid image registration: how to extract invariant features, how to describe them, how to match them and how to use them to compute a homography. Most importantly, this should give you some feeling about the strengths and weaknesses of local feature-based approaches.\n",
    "It should be noted that before you start this activity, you should read Lowe’s paper on SIFT:\n",
    "\n",
    "David G. Lowe, \"Distinctive image features from scale-invariant keypoints,\" International Journal of Computer Vision, 60, 2 (2004), pp. 91-110.\n",
    "The paper can be downloaded from [here](http://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf).\n",
    "\n",
    "This lab requires working in teams of two (exceptionally three) students. The labs will be organized on the first lab session by the professor who acts as lab instructor.\n",
    "\n",
    "Students will have to:\n",
    "\n",
    "1. Test Lowe’s implementation on a set of images showing some skin lesions.\n",
    "2. Register the images pairs corresponding to the same skin lesion using Lowe’s implementation to detect and match features, and implementing different motion models by estimating homography matrices.\n",
    "3. Improve the registration accuracy by means of data normalization for the homography estimation."
   ],
   "id": "KrPZaqmiq-D3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qYziQJIrq-D6"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ],
   "id": "qYziQJIrq-D6"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d2uKbqhvq-D3"
   },
   "source": [
    "## Additional tools\n",
    "In this lab, we will also make use of:\n",
    "- NumPy, a popular library for scientific computing\n",
    "- Matplotlib, a popular library for plotting data\n",
    "- Routines in the aux_utils.py file, which should already be in the local directory\n",
    "- Opencv\n",
    "-..."
   ],
   "id": "d2uKbqhvq-D3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "maCLffZBq-D4"
   },
   "outputs": [],
   "source": [
    "import math, copy\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')\n",
    "#from aux_utils import plt_house_x, plt_contour_wgrad, plt_gradients, plt_cost_vs_theta1\n",
    "from google.colab import files\n",
    "# import time\n",
    "from IPython import display\n",
    "from time import sleep\n",
    "# import opencv\n",
    "import cv2\n",
    "from google.colab.patches import cv2_imshow\n",
    "\n",
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "#Import math Library\n",
    "import math\n",
    "import scipy.linalg as linalg"
   ],
   "id": "maCLffZBq-D4"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N4XaiQjIq-D7"
   },
   "source": [
    "## Detect SIFT Keypoints and Descriptors\n",
    "Now we will register real images.\n",
    "\n",
    "Register skin1.png with skin2.png\n",
    "\n",
    "First, load and show the images.\n",
    "\n",
    "Also set SIFT to detect keypoints on images\n",
    "\n",
    "$\\color{yellow}{\\text{To be done during 1st lab session}}$"
   ],
   "id": "N4XaiQjIq-D7"
  },
  {
   "cell_type": "code",
   "source": [
    "skin_1 = cv2.imread(\"data/skin1.png\")\n",
    "skin_2 = cv2.imread(\"data/skin2.png\")\n",
    "\n",
    "plt.imshow(skin_1)\n",
    "plt.imshow(skin_2)\n",
    "# cvt color\n",
    "gray_1= cv2.cvtColor(skin_1,cv2.COLOR_BGR2GRAY)\n",
    "gray_2= cv2.cvtColor(skin_2,cv2.COLOR_BGR2GRAY)\n",
    "# detect\n",
    "sift = cv2.SIFT_create()\n",
    "kp_1, des_1 = sift.detectAndCompute(gray_1, None)\n",
    "kp_2, des_2 = sift.detectAndCompute(gray_2, None)"
   ],
   "metadata": {
    "id": "lt2c0aKeJ1cc"
   },
   "id": "lt2c0aKeJ1cc",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C6u74PmIq-D8"
   },
   "source": [
    "## Plot the Keypoints\n",
    "$\\color{yellow}{\\text{To be done during 1st lab session}}$"
   ],
   "id": "C6u74PmIq-D8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5hXdBqrlvZ2t"
   },
   "outputs": [],
   "source": [],
   "id": "5hXdBqrlvZ2t"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8XghO2acwhsi"
   },
   "source": [
    "## Compute Brute Force Matching\n",
    "\n",
    "$\\color{yellow}{\\text{To be done during 1st lab session}}$"
   ],
   "id": "8XghO2acwhsi"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kQTbCK41q-D7"
   },
   "outputs": [],
   "source": [],
   "id": "kQTbCK41q-D7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plot matches\n",
    "\n",
    "$\\color{yellow}{\\text{To be done during 1st lab session}}$"
   ],
   "metadata": {
    "id": "oGSJlvrMSbVP"
   },
   "id": "oGSJlvrMSbVP"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lVYs3ZWVxhrl"
   },
   "outputs": [],
   "source": [],
   "id": "lVYs3ZWVxhrl"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E-G7W7Ir1pWp"
   },
   "source": [
    "## Lowe match\n",
    "\n",
    "Now implement by yourself a function to match keypoints and descriptors between these 2 images\n",
    "\n",
    "Implement the function `SIFT_match` following the article \"Distinctive image features from scale-invariant keypoints\" David G. Lowe.\n",
    "\n",
    "$\\color{yellow}{\\text{To be done during 1st lab session}}$"
   ],
   "id": "E-G7W7Ir1pWp"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0VIECLXI1rwJ"
   },
   "outputs": [],
   "source": [],
   "id": "0VIECLXI1rwJ"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Recompute the matches using your function\n",
    "\n",
    "$\\color{yellow}{\\text{To be done during 1st lab session}}$"
   ],
   "metadata": {
    "id": "xaLsmGiqStUm"
   },
   "id": "xaLsmGiqStUm"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QzUHm9iZ12v8"
   },
   "outputs": [],
   "source": [
    "\n"
   ],
   "id": "QzUHm9iZ12v8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plot the new matches\n",
    "\n",
    "$\\color{yellow}{\\text{To be done during 1st lab session}}$"
   ],
   "metadata": {
    "id": "DAG7oloOSzE4"
   },
   "id": "DAG7oloOSzE4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZzHCd_te2LY9"
   },
   "outputs": [],
   "source": [],
   "id": "ZzHCd_te2LY9"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "idlegun72ctm"
   },
   "source": [
    "## Compute Homographies\n",
    "\n",
    "Compute the homography between both images using opencv function `cv2.findHomography`\n",
    "\n",
    "Plot one of the images warped acording to the obtained Homograhy\n",
    "\n",
    "$\\color{yellow}{\\text{To be done during 1st lab session}}$"
   ],
   "id": "idlegun72ctm"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lnlWP5s62faE"
   },
   "outputs": [],
   "source": [],
   "id": "lnlWP5s62faE"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Homography estimation\n",
    "\n",
    "$\\color{yellow}{\\text{To be done during 2nd lab session}}$"
   ],
   "metadata": {
    "id": "Y9Rw7vHJKC0s"
   },
   "id": "Y9Rw7vHJKC0s"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YgBsVdMVX_8u"
   },
   "source": [
    "Next, we will load images `00.png`, `01.png`, `02.png` and `03.png`"
   ],
   "id": "YgBsVdMVX_8u"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "axjQd3q5iEd8"
   },
   "outputs": [],
   "source": [
    "img00c = cv2.imread(\"00.png\")\n",
    "img01c = cv2.imread(\"01.png\")\n",
    "img02c = cv2.imread(\"02.png\")\n",
    "img03c = cv2.imread(\"03.png\")"
   ],
   "id": "axjQd3q5iEd8"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5_d9AQPwBOJh"
   },
   "source": [
    "And the csv files with keypoints"
   ],
   "id": "5_d9AQPwBOJh"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iGFcilcSBM6P"
   },
   "outputs": [],
   "source": [
    "keypoints_00 = genfromtxt('Keypoints_00.csv', delimiter=',', skip_header = 0)\n",
    "keypoints_01 = genfromtxt('Keypoints_01.csv', delimiter=',', skip_header = 0)\n",
    "keypoints_02 = genfromtxt('Keypoints_02.csv', delimiter=',', skip_header = 0)\n",
    "keypoints_03 = genfromtxt('Keypoints_03.csv', delimiter=',', skip_header = 0)\n",
    "\n",
    "print(np.shape(keypoints_00))\n",
    "print(keypoints_00)"
   ],
   "id": "iGFcilcSBM6P"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YLFihAkHq7IA"
   },
   "source": [
    "Now plot img00c, img01c, img02c, img03c all images using `cv2_imshow` from `opencv`"
   ],
   "id": "YLFihAkHq7IA"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qVlRs0K0pRHY"
   },
   "outputs": [],
   "source": [],
   "id": "qVlRs0K0pRHY"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sB5fbwlxB12e"
   },
   "source": [
    "Plot Keypoints on images."
   ],
   "id": "sB5fbwlxB12e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_2eMlQo5B01b"
   },
   "outputs": [],
   "source": [],
   "id": "_2eMlQo5B01b"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "waKlKc6oUagA"
   },
   "source": [
    "## Compute Homography\n",
    "\n",
    "Implement the function:\n",
    "\n",
    "H = computeHomography(features, matches, model)\n",
    "\n",
    "where model can be ('Euclidean', 'Similarity', 'Affine', 'Porjective')\n",
    "\n",
    "follow your notes from MIRA lessons, don't use any opencv existing function"
   ],
   "id": "waKlKc6oUagA"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1iMQKDxzVGeQ"
   },
   "outputs": [],
   "source": [
    "\n"
   ],
   "id": "1iMQKDxzVGeQ"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VlZa8D_BnTS6"
   },
   "source": [
    "##Compute Eucliedean Homography\n",
    "\n",
    "Compute the Euclidean Homography between all loaded images\n",
    "\n",
    "After computing them use the function `cv2.warpPerspective` to check the obtainen result"
   ],
   "id": "VlZa8D_BnTS6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fj7wBGD_8Kiz"
   },
   "outputs": [],
   "source": [
    "\n"
   ],
   "id": "Fj7wBGD_8Kiz"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N_rUXaHHiX-L"
   },
   "source": [
    "##Compute Similarity Homography\n",
    "Compute the Similarity Homography between all loaded images\n",
    "\n",
    "After computing them use the function `cv2.warpPerspective` to check the obtainen result"
   ],
   "id": "N_rUXaHHiX-L"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9RjF6VbGiWf4"
   },
   "outputs": [],
   "source": [],
   "id": "9RjF6VbGiWf4"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5U_1CATmih_V"
   },
   "source": [
    "##Compute Affine Homography\n",
    "\n",
    "Compute the Affine Homography between all loaded images\n",
    "\n",
    "After computing them use the function `cv2.warpPerspective` to check the obtainen result"
   ],
   "id": "5U_1CATmih_V"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dnKNn4f7igyw"
   },
   "outputs": [],
   "source": [],
   "id": "dnKNn4f7igyw"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nu5pj88Zil6v"
   },
   "source": [
    "##Compute Projective Homography\n",
    "\n",
    "Compute the Euclidean Homography between all loaded images\n",
    "\n",
    "After computing them use the function `cv2.warpPerspective` to check the obtainen result"
   ],
   "id": "Nu5pj88Zil6v"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wJp9k4_qi3B7"
   },
   "outputs": [],
   "source": [],
   "id": "wJp9k4_qi3B7"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OKsn3ROmKFyz"
   },
   "source": [
    "##Comment the previous obtained results.\n",
    "\n",
    "Which is the best homography for each image pair? Why?"
   ],
   "id": "OKsn3ROmKFyz"
  },
  {
   "cell_type": "markdown",
   "source": [
    "$\\color{red}{\\text{ANSWER}}$"
   ],
   "metadata": {
    "id": "gnWXMgkiJbfK"
   },
   "id": "gnWXMgkiJbfK"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compute Homography with skin images"
   ],
   "metadata": {
    "id": "oeJfH_93K08O"
   },
   "id": "oeJfH_93K08O"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now Compute the Homography between the 2 skin images used during the first sesion using your Homography Computation function. Use all models and and compare the results"
   ],
   "metadata": {
    "id": "6yXBDRkXTcGP"
   },
   "id": "6yXBDRkXTcGP"
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "XzqkPz1RTeAM"
   },
   "id": "XzqkPz1RTeAM",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## You should notice that you have outliers when you compute the Homography.\n",
    "\n",
    "Implement RANSAC function and recompute all the Homographies using it.\n",
    "\n",
    "Finally Warp one of the images and compare your results with the ones obtained using opencv functions."
   ],
   "metadata": {
    "id": "Qf7WInf_Tecf"
   },
   "id": "Qf7WInf_Tecf"
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "9gaM7arrTe0O"
   },
   "id": "9gaM7arrTe0O",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Extra Work"
   ],
   "metadata": {
    "id": "414WcufVLJqB"
   },
   "id": "414WcufVLJqB"
  },
  {
   "cell_type": "markdown",
   "source": [
    "There are many ways to apply *Deep Learning* for registering images. Do some research and find a solution that uses it and apply it to skin1 and skin2 images."
   ],
   "metadata": {
    "id": "n6iuCbvLLOaw"
   },
   "id": "n6iuCbvLLOaw"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tsNGbL6Zq-EL"
   },
   "source": [
    "\n",
    "## Congratulations!\n",
    "In this lab you:\n",
    "- tested SIFT Algorithm\n",
    "- implemented homography computation"
   ],
   "id": "tsNGbL6Zq-EL"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LmAB0g26lyYm"
   },
   "source": [
    "Submit this notebook by the lab deadline, with the cells executed and including your **answers** in the text fields in $\\color{red}{\\text{red}}$ color."
   ],
   "id": "LmAB0g26lyYm"
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "dl_toc_settings": {
   "rndtag": "40291"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
